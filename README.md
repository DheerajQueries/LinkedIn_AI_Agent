Step 1: Setting Up Your Project Workspace -> This first step is crucial because it creates a dedicated and clean space for your project. 
Think of it like setting up a new, organized workbench before you start building.

Action 1: Create a Project Folder -> LinkedIn_AI_Agent.
This folder will serve as the home for all files related to this project.

Action 2: Create a Virtual Environment cd path/to/your/linkedin_ai_agent -> Run the command > python -m venv venv. 
This command creates a "virtual environment" inside your project folder (in a new sub-folder named venv).

Action 3: Activate the Virtual Environment (Activating the environment tells your terminal, "From now on, for any Python-related command I run, use the tools and Python version inside this project's venv folder). Command to run -> venv\Scripts\activate

Step 2: Installing the Necessary Libraries 
Action 1: Create a requirements.txt File 
Action 2: Define Your Project's Dependencies

Below are the requirements:
Google Genai: This is the official library from Google. It's what allows your Python script to communicate directly with the Google models (like Gemini 1.5 pro) to generate text. Itâ€™s the engine that will write the LinkedIn posts.

langchanin-google-genai: This is a specific LangChain package that acts as a bridge, allowing the main LangChain framework to connect seamlessly with the Google library.

google-search-results: This library is a wrapper for a service called SerpApi. It allows your Python script to perform a Google search and get back clean, structured results. This is the tool your fact-checking agent will use to verify claims.

python-dotenv: This is a small but vital utility for security. It allows your program to load sensitive information, like API keys, from a local file (.env) instead of writing them directly into your code. 

langchain-community

Action 3: Install Everything from Your List
Run the command to install -> pip install -r requirements.txt


Step 3: Acquiring and Storing Your API Keys

Action 1: Get Your Google AI (Gemini) API Key
Action 2: Get Your SerpApi API Key
Action 3: Create/Update Your .env File

Open the newly created .env file and the code below
GOOGLE_API_KEY="your_google_ai_api_key_here"
SERPAPI_API_KEY="your_serpapi_api_key_here"


Step 4: Building the Post-Generation Agent (with Gemini)

Action 1: Create Your Main Python File
What to do: In your project folder (linkedin_ai_agent), create a new file named main.py.
Why we are doing this: This will be the central script for our project. We will run this single file to execute the entire process, from generating posts to fact-checking them.


Action 2: Load Your API Keys and Import Libraries (Add below code to the main.py file)

# For loading environment variables (the keys)
from dotenv import load_dotenv
import os

# LangChain components for Google Gemini
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# --- Step 1: Load Environment Variables ---
# This command finds the .env file and loads the variables
load_dotenv()

# We can now access the keys using os.getenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
serpapi_api_key = os.getenv("SERPAPI_API_KEY")

print("API Keys loaded successfully.")

The first three import statements bring in the necessary tools we installed earlier.
load_dotenv() is the command that actually reads your .env file.
os.getenv("YOUR_KEY_NAME") securely retrieves the keys from the loaded environment, so we can use them in the script without ever writing the actual key strings here.

